"""
NL2SQL ç³»ç»Ÿè¯„ä¼°å·¥å…·
ä½¿ç”¨ dev.json æ•°æ®é›†è°ƒç”¨ API è¯„ä¼°ç³»ç»Ÿæ€§èƒ½
"""

import json
import sys
import os
import requests
import time
from typing import List, Dict, Tuple
from collections import defaultdict
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


class NL2SQLEvaluator:
    """NL2SQL è¯„ä¼°å™¨"""
    
    def __init__(self, dataset_path: str, api_url: str = "http://localhost:8002/api/v1/nl2sql/generate"):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            dataset_path: æ•°æ®é›†æ–‡ä»¶è·¯å¾„
            api_url: API æ¥å£åœ°å€
        """
        self.dataset_path = dataset_path
        self.api_url = api_url
        self.data = []
        self.load_dataset()
    
    def load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {self.dataset_path}")
        
        with open(self.dataset_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.data)} æ¡æ•°æ®\n")
    
    def analyze_dataset(self):
        """åˆ†ææ•°æ®é›†ç»“æ„"""
        print("=" * 80)
        print("ğŸ“Š æ•°æ®é›†åˆ†æ")
        print("=" * 80)
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"\n1ï¸âƒ£  åŸºæœ¬ä¿¡æ¯:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(self.data)}")
        print(f"   æ ·æœ¬å­—æ®µ: {list(self.data[0].keys())}")
        
        # æ•°æ®åº“ç»Ÿè®¡
        db_counts = defaultdict(int)
        for item in self.data:
            db_counts[item['db_id']] += 1
        
        print(f"\n2ï¸âƒ£  æ•°æ®åº“åˆ†å¸ƒ:")
        print(f"   å”¯ä¸€æ•°æ®åº“æ•°: {len(db_counts)}")
        print(f"   å‰5ä¸ªæ•°æ®åº“:")
        for i, (db_id, count) in enumerate(sorted(db_counts.items(), key=lambda x: -x[1])[:5], 1):
            print(f"     {i}. {db_id}: {count} æ¡æŸ¥è¯¢")
        
        # SQL ç±»å‹ç»Ÿè®¡
        agg_types = defaultdict(int)
        cond_conn_types = defaultdict(int)
        
        for item in self.data:
            sql = item['sql']
            # èšåˆç±»å‹
            for agg in sql.get('agg', []):
                agg_types[agg] += 1
            # æ¡ä»¶è¿æ¥ç±»å‹
            cond_conn_types[sql.get('cond_conn_op', 0)] += 1
        
        print(f"\n3ï¸âƒ£  SQL ç‰¹å¾ç»Ÿè®¡:")
        print(f"   èšåˆå‡½æ•°åˆ†å¸ƒ:")
        agg_names = {0: 'NONE', 1: 'MAX', 2: 'MIN', 3: 'COUNT', 4: 'COUNT', 5: 'SUM', 6: 'AVG'}
        for agg, count in sorted(agg_types.items()):
            print(f"     {agg_names.get(agg, f'AGG_{agg}')}: {count}")
        
        print(f"\n   æ¡ä»¶è¿æ¥ç¬¦åˆ†å¸ƒ:")
        conn_names = {0: 'NONE', 1: 'AND', 2: 'OR'}
        for conn, count in sorted(cond_conn_types.items()):
            print(f"     {conn_names.get(conn, f'CONN_{conn}')}: {count}")
        
        # é—®é¢˜é•¿åº¦ç»Ÿè®¡
        question_lengths = [len(item['question']) for item in self.data]
        avg_length = sum(question_lengths) / len(question_lengths)
        
        print(f"\n4ï¸âƒ£  é—®é¢˜ç‰¹å¾:")
        print(f"   å¹³å‡é—®é¢˜é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
        print(f"   æœ€çŸ­é—®é¢˜: {min(question_lengths)} å­—ç¬¦")
        print(f"   æœ€é•¿é—®é¢˜: {max(question_lengths)} å­—ç¬¦")
        
        # æ ·æœ¬ç¤ºä¾‹
        print(f"\n5ï¸âƒ£  æ•°æ®æ ·æœ¬ç¤ºä¾‹:")
        for i in range(min(3, len(self.data))):
            item = self.data[i]
            print(f"\n   ç¤ºä¾‹ {i+1}:")
            print(f"     æ•°æ®åº“ID: {item['db_id']}")
            print(f"     é—®é¢˜: {item['question']}")
            print(f"     SQL: {item['query']}")
            print(f"     é—®é¢˜ID: {item['question_id']}")
    
    def get_evaluation_subset(self, n: int = 100) -> List[Dict]:
        """
        è·å–è¯„ä¼°å­é›†
        
        Args:
            n: å­é›†å¤§å°
            
        Returns:
            è¯„ä¼°æ ·æœ¬åˆ—è¡¨
        """
        import random
        
        # ç¡®ä¿å¯é‡ç°
        random.seed(42)
        
        # æŒ‰æ•°æ®åº“åˆ†å±‚é‡‡æ ·
        db_samples = defaultdict(list)
        for item in self.data:
            db_samples[item['db_id']].append(item)
        
        # ä»æ¯ä¸ªæ•°æ®åº“é‡‡æ ·
        subset = []
        samples_per_db = max(1, n // len(db_samples))
        
        for db_id, samples in db_samples.items():
            subset.extend(random.sample(samples, min(samples_per_db, len(samples))))
        
        # å¦‚æœä¸å¤Ÿ,å†éšæœºè¡¥å……
        if len(subset) < n:
            remaining = [item for item in self.data if item not in subset]
            subset.extend(random.sample(remaining, min(n - len(subset), len(remaining))))
        
        return subset[:n]
    
    def evaluate_prediction(
        self, 
        ground_truth: str, 
        prediction: str
    ) -> Tuple[bool, Dict]:
        """
        è¯„ä¼°å•ä¸ªé¢„æµ‹ç»“æœ
        
        Args:
            ground_truth: çœŸå®SQL
            prediction: é¢„æµ‹SQL
            
        Returns:
            (æ˜¯å¦å®Œå…¨åŒ¹é…, è¯„ä¼°è¯¦æƒ…)
        """
        # æ ‡å‡†åŒ–SQL (å»é™¤ç©ºæ ¼ã€å¤§å°å†™ç­‰)
        def normalize_sql(sql: str) -> str:
            sql = sql.strip().upper()
            sql = ' '.join(sql.split())
            return sql
        
        gt_norm = normalize_sql(ground_truth)
        pred_norm = normalize_sql(prediction)
        
        # å®Œå…¨åŒ¹é…
        exact_match = (gt_norm == pred_norm)
        
        # éƒ¨åˆ†åŒ¹é…è¯„ä¼°
        details = {
            'exact_match': exact_match,
            'gt_length': len(ground_truth),
            'pred_length': len(prediction),
            'has_select': 'SELECT' in pred_norm,
            'has_where': 'WHERE' in pred_norm,
            'has_and': 'AND' in pred_norm,
            'has_or': 'OR' in pred_norm,
        }
        
        return exact_match, details
    
    def call_api(self, db_id: str, question: str, dataset: str = "NL2SQL") -> Dict:
        """
        è°ƒç”¨ API ç”Ÿæˆ SQL
        
        Args:
            db_id: æ•°æ®åº“ ID
            question: è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            dataset: æ•°æ®é›†åç§°
            
        Returns:
            API å“åº”ç»“æœ
        """
        payload = {
            "db_id": db_id,
            "nl_query": question,
            "dataset": dataset
        }
        
        try:
            response = requests.post(self.api_url, json=payload, timeout=300)
            return response.json()
        except Exception as e:
            return {
                "status": "failed",
                "sql": None,
                "error": str(e)
            }
    
    def run_evaluation(
        self,
        subset_size: int = None,
        dataset: str = "NL2SQL",
        verbose: bool = True,
        save_errors: bool = True
    ) -> Dict:
        """
        è¿è¡Œè¯„ä¼°
        
        Args:
            subset_size: è¯„ä¼°æ ·æœ¬æ•° (None è¡¨ç¤ºå…¨éƒ¨)
            dataset: æ•°æ®é›†åç§°
            verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
            save_errors: æ˜¯å¦ä¿å­˜é”™è¯¯æ¡ˆä¾‹
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print("\n" + "=" * 80)
        print(f"ğŸ¯ å¼€å§‹è¯„ä¼°")
        print("=" * 80)
        print(f"API åœ°å€: {self.api_url}")
        print(f"æ•°æ®é›†: {dataset}")
        print(f"æ ·æœ¬æ•°: {subset_size if subset_size else 'å…¨éƒ¨'}")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        # ç¡®å®šè¯„ä¼°å­é›†
        if subset_size:
            subset = self.get_evaluation_subset(subset_size)
        else:
            subset = self.data
        
        results = {
            'total': len(subset),
            'exact_match': 0,
            'failed': 0,
            'success': 0,
            'total_time': 0,
            'details': [],
            'errors': []
        }
        
        start_time = time.time()
        
        for i, item in enumerate(subset, 1):
            print(f"\n[{i}/{len(subset)}] è¯„ä¼°ä¸­...")
            
            if verbose:
                print(f"  é—®é¢˜ID: {item['question_id']}")
                print(f"  æ•°æ®åº“: {item['db_id']}")
                print(f"  é—®é¢˜: {item['question']}")
                print(f"  æ ‡å‡†SQL: {item['query'][:80]}...")
            
            item_start = time.time()
            
            try:
                # è°ƒç”¨ API
                response = self.call_api(item['db_id'], item['question'], dataset)
                item_time = time.time() - item_start
                
                if response['status'] == 'success' and response.get('sql'):
                    predicted_sql = response['sql']
                    results['success'] += 1
                    
                    # è¯„ä¼°é¢„æµ‹ç»“æœ
                    exact_match, eval_details = self.evaluate_prediction(
                        item['query'],
                        predicted_sql
                    )
                    
                    if exact_match:
                        results['exact_match'] += 1
                        if verbose:
                            print(f"  âœ… å®Œå…¨åŒ¹é… ({item_time:.2f}s)")
                    else:
                        if verbose:
                            print(f"  âš ï¸  ä¸åŒ¹é… ({item_time:.2f}s)")
                            print(f"     é¢„æµ‹SQL: {predicted_sql[:80]}...")
                    
                    results['details'].append({
                        'question_id': item['question_id'],
                        'db_id': item['db_id'],
                        'question': item['question'],
                        'ground_truth': item['query'],
                        'prediction': predicted_sql,
                        'exact_match': exact_match,
                        'time': item_time,
                        **eval_details
                    })
                else:
                    # API è°ƒç”¨å¤±è´¥
                    results['failed'] += 1
                    error_msg = response.get('error', 'Unknown error')
                    
                    if verbose:
                        print(f"  âŒ API å¤±è´¥: {error_msg}")
                    
                    error_case = {
                        'question_id': item['question_id'],
                        'db_id': item['db_id'],
                        'question': item['question'],
                        'ground_truth': item['query'],
                        'error': error_msg,
                        'time': item_time
                    }
                    results['errors'].append(error_case)
                    results['details'].append({
                        **error_case,
                        'exact_match': False,
                        'prediction': None
                    })
                
                results['total_time'] += item_time
                
            except Exception as e:
                results['failed'] += 1
                item_time = time.time() - item_start
                results['total_time'] += item_time
                
                if verbose:
                    print(f"  âŒ å¼‚å¸¸: {str(e)}")
                
                error_case = {
                    'question_id': item['question_id'],
                    'db_id': item['db_id'],
                    'question': item['question'],
                    'ground_truth': item['query'],
                    'error': f"{type(e).__name__}: {str(e)}",
                    'time': item_time
                }
                results['errors'].append(error_case)
                results['details'].append({
                    **error_case,
                    'exact_match': False,
                    'prediction': None
                })
        
        # è®¡ç®—æŒ‡æ ‡
        total_time = time.time() - start_time
        accuracy = results['exact_match'] / results['total'] * 100 if results['total'] > 0 else 0
        avg_time = results['total_time'] / results['total'] if results['total'] > 0 else 0
        
        print("\n" + "=" * 80)
        print("ğŸ“ˆ è¯„ä¼°ç»“æœ")
        print("=" * 80)
        print(f"æ€»æ ·æœ¬æ•°: {results['total']}")
        print(f"æˆåŠŸç”Ÿæˆ: {results['success']} ({results['success']/results['total']*100:.2f}%)")
        print(f"å®Œå…¨åŒ¹é…: {results['exact_match']} (å‡†ç¡®ç‡: {accuracy:.2f}%)")
        print(f"å¤±è´¥æ•°é‡: {results['failed']}")
        print(f"æ€»è€—æ—¶: {total_time:.2f}s")
        print(f"å¹³å‡è€—æ—¶: {avg_time:.2f}s/æ ·æœ¬")
        print("=" * 80)
        
        # ä¿å­˜é”™è¯¯æ¡ˆä¾‹
        if save_errors and results['errors']:
            error_file = f"evaluation_errors_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(error_file, 'w', encoding='utf-8') as f:
                json.dump(results['errors'], f, ensure_ascii=False, indent=2)
            print(f"\nâŒ {len(results['errors'])} ä¸ªé”™è¯¯æ¡ˆä¾‹å·²ä¿å­˜åˆ°: {error_file}")
        
        return results
    
    def save_results(self, results: Dict, output_path: str):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='NL2SQL è¯„ä¼°å·¥å…·')
    parser.add_argument('--data', default='data/NL2SQL/dev.json', help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--api', default='http://localhost:8002/api/v1/nl2sql/generate', help='API åœ°å€')
    parser.add_argument('--dataset', default='NL2SQL', help='æ•°æ®é›†åç§°')
    parser.add_argument('--limit', type=int, help='è¯„ä¼°æ ·æœ¬æ•°é™åˆ¶')
    parser.add_argument('--output', default='evaluation_results.json', help='ç»“æœä¿å­˜è·¯å¾„')
    parser.add_argument('--analyze-only', action='store_true', help='ä»…åˆ†ææ•°æ®é›†,ä¸è¯„ä¼°')
    parser.add_argument('--quiet', action='store_true', help='ç®€åŒ–è¾“å‡º')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("NL2SQL è¯„ä¼°å·¥å…·")
    print("=" * 80)
    
    # åŠ è½½è¯„ä¼°å™¨
    evaluator = NL2SQLEvaluator(args.data, args.api)
    
    # åˆ†ææ•°æ®é›†
    if args.analyze_only:
        evaluator.analyze_dataset()
        return
    
    # è¿è¡Œè¯„ä¼°
    results = evaluator.run_evaluation(
        subset_size=args.limit,
        dataset=args.dataset,
        verbose=not args.quiet,
        save_errors=True
    )
    
    # ä¿å­˜ç»“æœ
    evaluator.save_results(results, args.output)
    
    print("\nâœ… è¯„ä¼°å®Œæˆ!")


if __name__ == "__main__":
    main()
